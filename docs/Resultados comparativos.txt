Resultados comparativos dos modelos (por extenso, completo e acad√™mico)

A tabela de resultados obtida no Orange apresenta as m√©tricas dos principais algoritmos de classifica√ß√£o aplicados ao dataset p33, cujo objetivo √© prever o cancelamento dos clientes.
As m√©tricas analisadas foram: AUC, Accuracy, F1-score, Precision, Recall e CA (classification accuracy do Orange).
Modelo com melhor desempenho

Com base nas m√©tricas apresentadas, o melhor modelo para o problema √©:

‚≠ê Regress√£o Log√≠stica
Justificativas:

Maior AUC de todos os modelos (0.864)
‚Üí Melhor capacidade de distinguir corretamente entre "cancelar" e "n√£o cancelar".

CA alta (0.831)
‚Üí Excelente taxa de acerto geral.

√ìtimo equil√≠brio entre precision, recall e F1
‚Üí N√£o s√≥ acerta muito, mas erra pouco.

Modelo simples, est√°vel e com baixa vari√¢ncia
‚Üí Evita overfitting, diferente da √Årvore.

Desempenho superior at√© mesmo √† Rede Neural e ao Random Forest, que normalmente s√£o muito fortes.

üß† 6. Conclus√£o Geral

Ap√≥s a compara√ß√£o dos modelos no Orange, conclui-se que a Regress√£o Log√≠stica foi o modelo mais eficaz para prever cancelamentos no dataset p33.
Ela apresentou o maior AUC, alta acur√°cia, boa estabilidade, al√©m de excelente equil√≠brio nas m√©tricas de classifica√ß√£o.

Em segundo lugar ficaram a Rede Neural e o Random Forest, que tamb√©m ofereceram desempenho robusto, por√©m ligeiramente inferiores ao modelo vencedor.

üîé üî∏ Logistic Regression

AUC: 0.864

CA: 0.831

Precision: 0.821

Recall: 0.831

F1-score: 0.498

‚û°Ô∏è An√°lise:
A Regress√£o Log√≠stica apresentou excelente desempenho global.
√â o modelo com maior AUC entre todos (0.864), mostrando forte capacidade de separa√ß√£o entre canceladores e n√£o canceladores.
Tamb√©m apresenta √≥timo equil√≠brio entre precision e recall, o que significa que acerta bem e erra pouco.

üîé üî∏ kNN

AUC: 0.653

CA: 0.758

Precision: 0.728

Recall: 0.758

F1-score: 0.240

‚û°Ô∏è An√°lise:
O kNN teve o segundo pior AUC entre os modelos.
Apesar de uma accuracy aceit√°vel (0.758), o F1-score √© fraco, indicando dificuldade para classificar casos mais complexos.
√â sens√≠vel a escala e varia√ß√£o dos dados.

üîé üî∏ Tree (√Årvore de Decis√£o)

AUC: 0.623

CA: 0.762

Precision: 0.755

Recall: 0.762

F1-score: 0.325

‚û°Ô∏è An√°lise:
Apresentou o pior AUC (0.623).
Embora tenha boa acur√°cia, √°rvores tendem a sofrer overfitting, explicando a queda no AUC e equil√≠brio ruim entre classes.

üîé üî∏ Random Forest

AUC: 0.815

CA: 0.821

Precision: 0.809

Recall: 0.821

F1-score: 0.466

‚û°Ô∏è An√°lise:
O Random Forest apresentou excelente desempenho geral.
√â est√°vel, robusto e melhora o desempenho da √°rvore individual.
Teve a segunda maior AUC (0.815), ficando atr√°s apenas da Regress√£o Log√≠stica.

üîé üî∏ Neural Network

AUC: 0.852

CA: 0.829

Precision: 0.819

Recall: 0.829

F1-score: 0.496

‚û°Ô∏è An√°lise:
O desempenho da rede neural foi muito bom, superando Random Forest e SVM, com AUC alto (0.852).
Mostra capacidade de capturar rela√ß√µes n√£o lineares no dataset.

